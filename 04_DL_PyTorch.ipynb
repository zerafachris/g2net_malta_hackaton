{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:05.960230Z",
     "start_time": "2020-02-07T08:50:01.754757Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:11.350207Z",
     "start_time": "2020-02-07T08:50:05.962761Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/df_train.pkl.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:11.388771Z",
     "start_time": "2020-02-07T08:50:11.352657Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:11.394582Z",
     "start_time": "2020-02-07T08:50:11.391091Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare & Check data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:11.406804Z",
     "start_time": "2020-02-07T08:50:11.396695Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['label','target','trace_id','E','N','Z'],axis=1)\n",
    "Y = df['target']\n",
    "\n",
    "print('X : ')\n",
    "print(X.count())\n",
    "print()\n",
    "print('Y: ')\n",
    "print(Y.count())\n",
    "\n",
    "Y_labels = Y\n",
    "Y_count_labels = len(set(Y))\n",
    "\n",
    "print()\n",
    "print('Distinct classes :', Y_count_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:25.014763Z",
     "start_time": "2020-02-07T08:50:11.408651Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('./data/df_train.pkl.gzip', compression='gzip')[['E','N','Z']]\n",
    "X_test = pd.read_pickle('./data/df_test.pkl.gzip', compression='gzip')[['E','N','Z']]\n",
    "y_train = pd.read_pickle('./data/df_train.pkl.gzip', compression='gzip')['target']\n",
    "y_test = pd.read_pickle('./data/df_test.pkl.gzip', compression='gzip')['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:25.021606Z",
     "start_time": "2020-02-07T08:50:25.018086Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('Y_train: ', y_train.shape)\n",
    "print('Y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:26.915730Z",
     "start_time": "2020-02-07T08:50:25.024380Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.stack([np.stack([e,n,z], axis=1)\n",
    "                    for e,n,z in zip(X_train['E'],X_train['N'], X_train['Z']) ], axis=0)\n",
    "X_test  = np.stack([np.stack([e,n,z], axis=1)\n",
    "                    for e,n,z in zip(X_test['E'],X_test['N'], X_test['Z']) ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train.to_numpy())\n",
    "y_test = torch.from_numpy(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.transpose(1, 2)\n",
    "X_test = X_test.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T08:50:26.934279Z",
     "start_time": "2020-02-07T08:50:26.927356Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('Y_train: ', y_train.shape)\n",
    "print('Y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 32 #number of channerls per conv layer\n",
    "k_size = 3 #size of the convolution kernel\n",
    "depth = 7\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(3, c, kernel_size=k_size, padding=1, stride=2)])\n",
    "        self.convs.extend([nn.Conv1d(c, c, kernel_size=k_size, padding=1, stride=2)\n",
    "                           for _ in range(10)])\n",
    "        self.fc1 = nn.Linear(96, 48)\n",
    "        self.fc2 = nn.Linear(48, 7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.convs):\n",
    "            x = torch.relu(self.convs[i](x))\n",
    "        x = x.view(-1, 96)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "network = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "network.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network(X_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 2000\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = network(X)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out_test = network(X_test)\n",
    "            val_loss = loss_fn(out_test, y_test)\n",
    "        # if (i+1) % 300 == 0:\n",
    "        print(f'Epoch {epoch}, Step {i}, Loss {loss.item()}, Val loss {val_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = network(X_test)\n",
    "\n",
    "y_pred_cls = y_pred.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_cls))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
